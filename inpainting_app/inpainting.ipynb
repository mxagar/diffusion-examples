{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f123c733",
   "metadata": {},
   "source": [
    "# In-Painting Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8148da05",
   "metadata": {},
   "source": [
    "In this small project, the foreground/background of an image is automatically segmented and can be replaced by a generated image, conditioned by a text prompt.\n",
    "\n",
    "- [SAM](#) is used as segmentation model.\n",
    "- [Stable Diffusion XL Turbo](#) is used as in-painting model.\n",
    "- [Gradio](#) is used as web UI engine.\n",
    "\n",
    "As you can see, all models and tools come from [HuggingFace](#).\n",
    "\n",
    "Here's an example:\n",
    "\n",
    "TBD.\n",
    "\n",
    "Table of contents:\n",
    "\n",
    "- [Setup](#setup)\n",
    "- [Zero-Shot Image Segmenation with SAM](#zero-shot-image-segmenation-with-sam)\n",
    "- [In-Painting](#in-painting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c0a47b",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "481305c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import SamModel, SamProcessor\n",
    "from diffusers import DiffusionPipeline, AutoPipelineForText2Image, AutoPipelineForInpainting\n",
    "from diffusers.utils import load_image, make_image_grid\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d52394cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 NVIDIA GeForce RTX 3060\n",
      "1 NVIDIA T500\n"
     ]
    }
   ],
   "source": [
    "# Name of each GPU\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(i, torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99f199b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ed31f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec  7 16:21:03 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA T500                    On  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   51C    P8            N/A  / 5001W |       5MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 3060        On  |   00000000:52:00.0 Off |                  N/A |\n",
      "|  0%   36C    P8             13W /  170W |    4170MiB /  12288MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            4403      G   /usr/bin/gnome-shell                      1MiB |\n",
      "|    1   N/A  N/A            4327      G   ...c/gnome-remote-desktop-daemon          2MiB |\n",
      "|    1   N/A  N/A            4403      G   /usr/bin/gnome-shell                      2MiB |\n",
      "|    1   N/A  N/A         2054628      C   ...iconda3/envs/genai/bin/python        506MiB |\n",
      "|    1   N/A  N/A         2665274      C   ...iconda3/envs/genai/bin/python       3628MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13ea1bb",
   "metadata": {},
   "source": [
    "## Zero-Shot Image Segmenation with SAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cce7e89",
   "metadata": {},
   "source": [
    "[SAM](#) is ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28c0dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SAM processor + model and move to GPU\n",
    "sam_processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")\n",
    "sam_model = SamModel.from_pretrained(\"facebook/sam-vit-base\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3824a62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_rgba(mask: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Transform a binary mask into an RGBA image for visualization.\"\"\"\n",
    "    bg_transparent = np.zeros(mask.shape + (4, ), dtype=np.uint8)    \n",
    "    # Color the area we will replace in green\n",
    "    # (this vector is [Red, Green, Blue, Alpha])\n",
    "    bg_transparent[mask == 1] = [0, 255, 0, 127]\n",
    "\n",
    "    return bg_transparent\n",
    "\n",
    "\n",
    "def run_segmentation(\n",
    "    image: np.ndarray,\n",
    "    input_points: np.ndarray,\n",
    "    processor: SamProcessor,\n",
    "    model: SamModel,\n",
    "    device: str | torch.device = \"cuda:0\",\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Run SAM segmentation and return the best mask.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The input image as a NumPy array.\n",
    "        input_points (np.ndarray): The input points for SAM.\n",
    "        processor (SamProcessor): The SAM processor.\n",
    "        model (SamModel): The SAM model.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The best mask as a NumPy array.\n",
    "    \"\"\"\n",
    "    if isinstance(device, str):\n",
    "        device = torch.device(device)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Prepare inputs\n",
    "    inputs = processor(\n",
    "        images=image,\n",
    "        input_points=input_points,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    # Run model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Post-process the outputs of SAM to obtain the masks\n",
    "    masks = processor.image_processor.post_process_masks(\n",
    "       outputs.pred_masks.cpu(), \n",
    "       inputs[\"original_sizes\"].cpu(), \n",
    "       inputs[\"reshaped_input_sizes\"].cpu()\n",
    "    )\n",
    "    \n",
    "    # Select the mask with the highest score\n",
    "    best_mask = masks[0][0][outputs.iou_scores.argmax()] \n",
    "\n",
    "    # Invert the mask:\n",
    "    # subject pixels will have a value of 0 \n",
    "    # and the background pixels a value of 1.\n",
    "    # This will make it more convenient\n",
    "    # to infill the background\n",
    "    return ~best_mask.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f140576",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f1c4f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=128x128>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example image\n",
    "raw_image = Image.open(\"./assets/car.png\").convert(\"RGB\").resize((512, 512))\n",
    "\n",
    "# Coordinates of two points on the car\n",
    "input_points = [[[150, 170], [300, 250]]]\n",
    "\n",
    "# Run segmentation\n",
    "mask = run_segmentation(raw_image, input_points, sam_processor, sam_model, device)\n",
    "\n",
    "# Visualize the mask\n",
    "Image.fromarray(mask_to_rgba(mask)).resize((128, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319b482f",
   "metadata": {},
   "source": [
    "## In-Painting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101e194c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
